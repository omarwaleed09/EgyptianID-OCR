{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c284d07e-f250-4e2b-86e0-6c5b03a98ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to file\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Affine(rotate=(-3, 3), shear=(-2, 2), p=0.3),\n",
    "    #A.OneOf([\n",
    "    #    A.MotionBlur(blur_limit=3, p=1),\n",
    "     #   A.GaussianBlur(blur_limit=(2, 4), p=1)\n",
    "    #], p=0.3),\n",
    "    A.Sharpen(alpha=(0.1, 0.3), lightness=(0.7, 1.0), p=0.3),\n",
    "    A.ColorJitter(\n",
    "        brightness=0.3,\n",
    "        contrast=0.3,\n",
    "        saturation=0.3,\n",
    "        hue=0.1,\n",
    "        p=0.6\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20,\n",
    "                         val_shift_limit=10, p=0.4),\n",
    "    A.ImageCompression(quality_range=(80, 100), p=0.4),\n",
    "    #A.GaussNoise(var_limit=(5, 20), p=0.3),\n",
    "    A.CLAHE(clip_limit=2, tile_grid_size=(2, 2), p=0.3),\n",
    "    A.ToGray(p=0.2),\n",
    "    A.Equalize(p=0.2),\n",
    "])\n",
    "\n",
    "input_folder = r\"../data/retrain_yolo_model\"\n",
    "output_folder = r\"..\\data\\retrain_yolo_model_aug\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "num_images = 20\n",
    "\n",
    "for img_path in glob(os.path.join(input_folder, \"*.jpg\")):\n",
    "    image = cv2.imread(img_path)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    for i in range(num_images):\n",
    "        augmented = transform(image=image)\n",
    "        aug_img = augmented[\"image\"]\n",
    "        cv2.imwrite(f\"{output_folder}/{base_name}aug{i}.jpg\", aug_img)\n",
    "\n",
    "print(\"saved to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ffc26-1c73-44fc-8c94-dedcaa947df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"D:\\ocr_project\\data\\dataset\\images\\train\\train\\id_sample4.webp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adebaf25-ba1b-4aeb-9579-4f7eb5cdeabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13168\\2947254968.py:27: UserWarning: Argument(s) 'scale_min, scale_max' are not valid for transform Downscale\n",
      "  A.Downscale(scale_min=0.97, scale_max=0.99, p=0.5),\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m num_images = \u001b[32m15\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_images):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     augmented = transform(image=image)\n\u001b[32m     43\u001b[39m     aug_img = augmented[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     44\u001b[39m     cv2.imwrite(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_aug_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.jpg\u001b[39m\u001b[33m\"\u001b[39m, aug_img)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ocr\\Lib\\site-packages\\albumentations\\core\\composition.py:610\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, force_apply, *args, **data)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;28mself\u001b[39m.preprocess(data)\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     data = t(**data)\n\u001b[32m    611\u001b[39m     \u001b[38;5;28mself\u001b[39m._track_transform_params(t, data)\n\u001b[32m    612\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.check_data_post_transform(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ocr\\Lib\\site-packages\\albumentations\\core\\composition.py:1012\u001b[39m, in \u001b[36mOneOf.__call__\u001b[39m\u001b[34m(self, force_apply, *args, **data)\u001b[39m\n\u001b[32m   1010\u001b[39m     idx: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28mself\u001b[39m.random_generator.choice(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.transforms), p=\u001b[38;5;28mself\u001b[39m.transforms_ps)\n\u001b[32m   1011\u001b[39m     t = \u001b[38;5;28mself\u001b[39m.transforms[idx]\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     data = t(force_apply=\u001b[38;5;28;01mTrue\u001b[39;00m, **data)\n\u001b[32m   1013\u001b[39m     \u001b[38;5;28mself\u001b[39m._track_transform_params(t, data)\n\u001b[32m   1014\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ocr\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:257\u001b[39m, in \u001b[36mBasicTransform.__call__\u001b[39m\u001b[34m(self, force_apply, *args, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.should_apply(force_apply=force_apply):\n\u001b[32m    256\u001b[39m     params = \u001b[38;5;28mself\u001b[39m.get_params()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     params = \u001b[38;5;28mself\u001b[39m.update_transform_params(params=params, data=kwargs)\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.targets_as_params:  \u001b[38;5;66;03m# check if all required targets are in kwargs.\u001b[39;00m\n\u001b[32m    260\u001b[39m         missing_keys = \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.targets_as_params).difference(kwargs.keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ocr\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:398\u001b[39m, in \u001b[36mBasicTransform.update_transform_params\u001b[39m\u001b[34m(self, params, data)\u001b[39m\n\u001b[32m    396\u001b[39m     shape = data[\u001b[33m\"\u001b[39m\u001b[33mvolumes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m].shape  \u001b[38;5;66;03m# Take first slice of first volume\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     shape = data[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m].shape\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    400\u001b[39m     shape = data[\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m].shape\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "import os\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Affine(rotate=(-3, 3), shear=(-2, 2), p=0.3),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=3, p=1),\n",
    "        A.GaussianBlur(blur_limit=(2, 4), p=1)\n",
    "    ], p=0.3),\n",
    "    A.Sharpen(alpha=(0.1, 0.3), lightness=(0.7, 1.0), p=0.3),\n",
    "    A.ColorJitter(\n",
    "        brightness=0.3,\n",
    "        contrast=0.3,\n",
    "        saturation=0.3,\n",
    "        hue=0.1,\n",
    "        p=0.6\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20,\n",
    "                         val_shift_limit=10, p=0.4),\n",
    "    A.ImageCompression(quality_range=(80, 100), p=0.4),\n",
    "    #A.GaussNoise(var_limit=(5, 20), p=0.3),\n",
    "    A.CLAHE(clip_limit=2, tile_grid_size=(2, 2), p=0.3),\n",
    "    A.ToGray(p=0.2),\n",
    "    A.Equalize(p=0.2),\n",
    "    A.Downscale(scale_min=0.97, scale_max=0.99, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=(1, 2), p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "\n",
    "input_path = r\"D:\\ocr_project\\notebooks\\outputs\\augmented_1_egypt_id_1ÙŠ (2)_religion.jpg\"\n",
    "output_folder = r\"D:\\ocr_project\\retrain_cnn_data\\train\\christian_f\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "image = cv2.imread(input_path)\n",
    "base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "\n",
    "num_images = 15\n",
    "\n",
    "for i in range(num_images):\n",
    "    augmented = transform(image=image)\n",
    "    aug_img = augmented[\"image\"]\n",
    "    cv2.imwrite(f\"{output_folder}/{base_name}_aug_{i}.jpg\", aug_img)\n",
    "\n",
    "\n",
    "print(\"saved to train_augmented_2 file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "414daa68-3385-47e3-9565-af8810d33d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13168\\241445687.py:32: UserWarning: Argument(s) 'scale_min, scale_max' are not valid for transform Downscale\n",
      "  A.Downscale(scale_min=0.97, scale_max=0.99, p=0.5),\n"
     ]
    }
   ],
   "source": [
    "#more data on blurred and pixeled\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Affine(rotate=(-3, 3), shear=(-2, 2), p=0.3),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=3, p=1),\n",
    "        A.GaussianBlur(blur_limit=(2, 4), p=1)\n",
    "    ], p=0.3),\n",
    "    A.Sharpen(alpha=(0.1, 0.3), lightness=(0.7, 1.0), p=0.3),\n",
    "    A.ColorJitter(\n",
    "        brightness=0.3,\n",
    "        contrast=0.3,\n",
    "        saturation=0.3,\n",
    "        hue=0.1,\n",
    "        p=0.6\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20,\n",
    "                         val_shift_limit=10, p=0.4),\n",
    "    A.ImageCompression(quality_range=(80, 100), p=0.4),\n",
    "    #A.GaussNoise(var_limit=(5, 20), p=0.3),\n",
    "    A.CLAHE(clip_limit=2, tile_grid_size=(2, 2), p=0.3),\n",
    "    A.ToGray(p=0.2),\n",
    "    A.Equalize(p=0.2),\n",
    "    A.Downscale(scale_min=0.97, scale_max=0.99, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=(1, 2), p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "\n",
    "input_folder = r\"D:\\ocr_project\\notebooks\\outputs\"\n",
    "output_folder = r\"D:\\ocr_project\\retrain_cnn_data\\train\\christian_f\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "num_images = 15\n",
    "\n",
    "for img_path in glob(os.path.join(input_folder, \"*.jpg\")):\n",
    "    image = cv2.imread(img_path)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    for i in range(num_images):\n",
    "        augmented = transform(image=image)\n",
    "        aug_img = augmented[\"image\"]\n",
    "        cv2.imwrite(f\"{output_folder}/{base_name}aug{i}.jpg\", aug_img)\n",
    "\n",
    "print(\"saved to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329d15d-eb8e-4d5d-a32b-f30436232701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671c66b-ca25-4817-82e0-2aa06b82e31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
