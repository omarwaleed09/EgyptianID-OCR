{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c9e32e-4761-4b17-befc-8c8399664ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import numpy as np\n",
    "import mapping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import splitfolders\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "from custom_layers.MinPooling import MinPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aabcf007-be8c-4037-9f76-8d7cfc06994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_marital_status={\n",
    "    \"single_m\": \"أعزب\",\n",
    "    \"single_f\": \"أنسة\",\n",
    "    \"married_m\": \"متزوج\",\n",
    "    \"married_f\": \"متزوجة\",\n",
    "    \"widow\": \"أرملة\",\n",
    "    \"widower\": \"أرمل\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa18101a-3160-4c46-8608-74fdea57eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2895 files belonging to 6 classes.\n",
      "Found 783 files belonging to 6 classes.\n",
      "Found 459 files belonging to 6 classes.\n",
      "Classes: ['married_f', 'married_m', 'single_f', 'single_m', 'widow', 'widower']\n"
     ]
    }
   ],
   "source": [
    "img_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "Marital_status_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    r\"..\\data\\dataset_cnn_2\\data\\Marital status\\train\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "Marital_status_val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    r\"..\\data\\dataset_cnn_2\\data\\Marital status\\val\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "Marital_status_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    r\"..\\data\\dataset_cnn_2\\data\\Marital status\\test\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "class_names_Marital_status = Marital_status_train_ds.class_names\n",
    "print(\"Classes:\", class_names_Marital_status)\n",
    "num_classes = len(class_names_Marital_status)\n",
    "\n",
    "Marital_status_train_ds = Marital_status_train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "Marital_status_val_ds = Marital_status_val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "Marital_status_test_ds = Marital_status_test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf209fae-602a-43b8-ba77-af1bcbe3d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    #layers.Conv2D(16, 3, activation='relu', input_shape=(64, 64, 3)),\n",
    "    #layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    MinPooling2D(pool_size=(2,2)),\n",
    "    #layers.MaxPooling2D(),\n",
    "    #layers.AveragePooling2D(pool_size=(2,2)),\n",
    "\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    #layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Conv2D(128, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Conv2D(256, 3, activation='relu'),\n",
    "    #layers.AveragePooling2D(pool_size=(2,2)),\n",
    "    MinPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb16e684-ede3-401e-9904-2e4a1aa0992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad47978-6e19-4cb1-a093-e24280077905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\envs\\ocr\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 632ms/step - accuracy: 0.7468 - loss: 0.6540 - val_accuracy: 0.9962 - val_loss: 0.0138\n",
      "Epoch 2/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 612ms/step - accuracy: 0.9903 - loss: 0.0359 - val_accuracy: 0.9949 - val_loss: 0.0187\n",
      "Epoch 3/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 673ms/step - accuracy: 0.9955 - loss: 0.0102 - val_accuracy: 0.9974 - val_loss: 0.0044\n",
      "Epoch 4/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 627ms/step - accuracy: 0.9959 - loss: 0.0095 - val_accuracy: 0.9962 - val_loss: 0.0159\n",
      "Epoch 5/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 621ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9974 - val_loss: 0.0057\n",
      "Epoch 6/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 1.5765e-04 - val_accuracy: 1.0000 - val_loss: 5.1846e-04\n",
      "Epoch 7/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 595ms/step - accuracy: 1.0000 - loss: 2.6288e-05 - val_accuracy: 1.0000 - val_loss: 7.4275e-04\n",
      "Epoch 8/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 590ms/step - accuracy: 1.0000 - loss: 1.4068e-05 - val_accuracy: 1.0000 - val_loss: 9.9890e-04\n",
      "Epoch 9/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 585ms/step - accuracy: 1.0000 - loss: 9.1249e-06 - val_accuracy: 0.9987 - val_loss: 0.0015\n",
      "Epoch 10/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 588ms/step - accuracy: 1.0000 - loss: 4.6084e-06 - val_accuracy: 0.9987 - val_loss: 0.0017\n",
      "Epoch 11/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 582ms/step - accuracy: 1.0000 - loss: 2.2350e-06 - val_accuracy: 0.9987 - val_loss: 0.0020\n",
      "Epoch 12/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 595ms/step - accuracy: 1.0000 - loss: 1.4552e-06 - val_accuracy: 0.9987 - val_loss: 0.0024\n",
      "Epoch 13/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 588ms/step - accuracy: 1.0000 - loss: 9.8575e-07 - val_accuracy: 0.9987 - val_loss: 0.0029\n",
      "Epoch 14/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 584ms/step - accuracy: 1.0000 - loss: 7.3143e-07 - val_accuracy: 0.9987 - val_loss: 0.0032\n",
      "Epoch 15/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 578ms/step - accuracy: 1.0000 - loss: 6.0783e-07 - val_accuracy: 0.9987 - val_loss: 0.0035\n",
      "Epoch 16/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 551ms/step - accuracy: 1.0000 - loss: 5.1865e-07 - val_accuracy: 0.9987 - val_loss: 0.0037\n",
      "Epoch 17/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 4.7081e-07 - val_accuracy: 0.9987 - val_loss: 0.0040\n",
      "Epoch 18/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 391ms/step - accuracy: 1.0000 - loss: 4.3449e-07 - val_accuracy: 0.9987 - val_loss: 0.0041\n",
      "Epoch 19/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 418ms/step - accuracy: 1.0000 - loss: 4.0048e-07 - val_accuracy: 0.9987 - val_loss: 0.0041\n",
      "Epoch 20/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 390ms/step - accuracy: 1.0000 - loss: 3.7462e-07 - val_accuracy: 0.9987 - val_loss: 0.0042\n",
      "Epoch 21/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 3.4975e-07 - val_accuracy: 0.9987 - val_loss: 0.0041\n",
      "Epoch 22/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 388ms/step - accuracy: 1.0000 - loss: 3.3736e-07 - val_accuracy: 0.9987 - val_loss: 0.0043\n",
      "Epoch 23/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 3.1673e-07 - val_accuracy: 0.9987 - val_loss: 0.0041\n",
      "Epoch 24/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 3.1105e-07 - val_accuracy: 0.9987 - val_loss: 0.0042\n",
      "Epoch 25/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 394ms/step - accuracy: 1.0000 - loss: 2.9153e-07 - val_accuracy: 0.9987 - val_loss: 0.0042\n",
      "Epoch 26/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 2.8066e-07 - val_accuracy: 0.9987 - val_loss: 0.0040\n",
      "Epoch 27/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 388ms/step - accuracy: 1.0000 - loss: 2.6559e-07 - val_accuracy: 0.9987 - val_loss: 0.0040\n",
      "Epoch 28/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 2.5476e-07 - val_accuracy: 0.9987 - val_loss: 0.0041\n",
      "Epoch 29/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 395ms/step - accuracy: 1.0000 - loss: 2.4644e-07 - val_accuracy: 0.9987 - val_loss: 0.0041\n",
      "Epoch 30/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 394ms/step - accuracy: 1.0000 - loss: 2.3578e-07 - val_accuracy: 0.9987 - val_loss: 0.0040\n",
      "Epoch 31/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 2.2713e-07 - val_accuracy: 0.9987 - val_loss: 0.0039\n",
      "Epoch 32/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 388ms/step - accuracy: 1.0000 - loss: 2.1556e-07 - val_accuracy: 0.9987 - val_loss: 0.0037\n",
      "Epoch 33/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 283ms/step - accuracy: 1.0000 - loss: 2.0630e-07 - val_accuracy: 0.9987 - val_loss: 0.0038\n",
      "Epoch 34/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.9979e-07 - val_accuracy: 0.9987 - val_loss: 0.0037\n",
      "Epoch 35/35\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 1.9728e-07 - val_accuracy: 0.9987 - val_loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Marital_status_train_ds, epochs=35, \n",
    "                    validation_data=Marital_status_val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129cfe27-31ad-40b0-ac92-26f0365eb123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9978 - loss: 0.0054\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(Marital_status_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d075fdc-deee-4ee7-9dc5-1beddb7907fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/predictions_CNN_muslim.txt\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"\"\n",
    "#D:\\ocr_project\\data\\dataset_cnn_2\\output_img\\result\\crops\\gender\\male\n",
    "#religion\\muslim_m   \"D:\\ocr_project\\data\\dataset_cnn_2\\output_img\\result\\crops\\gender\\male\"\n",
    "#marital status\\widower   \"..\\data\\dataset_cnn_2\\data\\test\\male\"\n",
    "output_file = \"../outputs/predictions_CNN_muslim.txt\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "       \n",
    "        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "      \n",
    "        img = image.load_img(img_path, target_size=(64,64))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = img_array / 255.0\n",
    "\n",
    "     \n",
    "        predictions = model.predict(img_array, verbose=0)\n",
    "        predicted_label = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "        en_label = class_names_Marital_status[predicted_label]\n",
    "        ar_label = label_map_marital_status.get(en_label, en_label)\n",
    "\n",
    "     \n",
    "        f.write(f\"{img_name}: {ar_label}\\n\")\n",
    "\n",
    "print(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351b4803-b7c0-463c-969d-9746f16476c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/cnn_model_marital_status.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0fccd9-6479-4864-9882-25bfbd98f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\envs\\ocr\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model(\"../models/cnn_model_marital_status.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84734e3d-6492-4fa1-9a0f-513b415a1439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
